{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119c9460",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Home assignment 05: Bagging and OOB score\n",
    "\n",
    "Please, fill the lines in the code below.\n",
    "This is a simplified version of `BaggingRegressor` from `sklearn`. Please, notice, that `sklearn` API is **not preserved**.\n",
    "\n",
    "Your algorithm should be able to train different instances of the same model class on bootstrapped datasets and to provide [OOB score](https://en.wikipedia.org/wiki/Out-of-bag_error) for the training set.\n",
    "\n",
    "The model should be passed as model class with no explicit parameters and no parentheses.\n",
    "\n",
    "Example:\n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "bagging_regressor.fit(LinearRegression, X, y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31ecde34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06110580",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimplifiedBaggingRegressor:\n",
    "    def __init__(self, num_bags, oob=False):\n",
    "        self.num_bags = num_bags\n",
    "        self.oob = oob\n",
    "        \n",
    "    def _generate_splits(self, data: np.ndarray):\n",
    "        '''\n",
    "        Generate indices for every bag and store in self.indices_list list\n",
    "        '''\n",
    "        self.indices_list = []\n",
    "        data_length = len(data)\n",
    "        for bag in range(self.num_bags):\n",
    "            self.indices_list.append(np.random.randint(0, data_length, data_length)) # Your Code Here\n",
    "        \n",
    "    def fit(self, model_constructor, data, target):\n",
    "        '''\n",
    "        Fit model on every bag.\n",
    "        Model constructor with no parameters (and with no ()) is passed to this function.\n",
    "        \n",
    "        example:\n",
    "        \n",
    "        bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "        bagging_regressor.fit(LinearRegression, X, y)\n",
    "        '''\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self._generate_splits(data)\n",
    "        assert len(set(list(map(len, self.indices_list)))) == 1, 'All bags should be of the same length!'\n",
    "        assert list(map(len, self.indices_list))[0] == len(data), 'All bags should contain `len(data)` number of elements!'\n",
    "        self.models_list = []\n",
    "        for bag in range(self.num_bags):\n",
    "            model = model_constructor()\n",
    "            data_bag, target_bag = data[self.indices_list[bag]], target[self.indices_list[bag]] # Your Code Here\n",
    "            self.models_list.append(model.fit(data_bag, target_bag)) # store fitted models here\n",
    "        if self.oob:\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "        \n",
    "    def predict(self, data):\n",
    "        '''\n",
    "        Get average prediction for every object from passed dataset\n",
    "        '''\n",
    "        # Your code here\n",
    "        result = []\n",
    "        for sample in data:\n",
    "            predicts = []\n",
    "            for model in self.models_list:\n",
    "                predicts.append(model.predict(sample.reshape(1, -1)))\n",
    "            result.append(np.mean(predicts))\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def _get_oob_predictions_from_every_model(self):\n",
    "        '''\n",
    "        Generates list of lists, where list i contains predictions for self.data[i] object\n",
    "        from all models, which have not seen this object during training phase\n",
    "        '''\n",
    "        # Your Code Here\n",
    "        list_of_predictions_lists = [[model.predict(self.data[i].reshape(1, -1)).item() for model in np.array(self.models_list)[np.array([i not in v for v in self.indices_list])]] for i in range(len(self.data))]\n",
    "        self.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)\n",
    "    \n",
    "    def _get_averaged_oob_predictions(self):\n",
    "        '''\n",
    "        Compute average prediction for every object from training set.\n",
    "        If object has been used in all bags on training phase, return None instead of prediction\n",
    "        '''\n",
    "        self._get_oob_predictions_from_every_model()\n",
    "        self.oob_predictions = [np.mean(preds) if len(preds) > 0 else None for preds in self.list_of_predictions_lists]# Your Code Here\n",
    "        \n",
    "        \n",
    "    def OOB_score(self):\n",
    "        '''\n",
    "        Compute mean square error for all objects, which have at least one prediction\n",
    "        '''\n",
    "        self._get_averaged_oob_predictions()\n",
    "        ms = []\n",
    "        for i,j in zip(self.oob_predictions, self.target):\n",
    "            if i is not None:\n",
    "                ms.append(np.square(i - j))\n",
    "        return np.mean(ms) # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa174f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Local tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaa2e710",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54221c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Simple tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84c94a8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e70f2e96f004f4ab79f73efe2168bbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple tests done!\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    X = np.random.randn(2000, 10)\n",
    "    y = np.mean(X, axis=1)\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    assert np.mean((predictions - y)**2) < 1e-6, 'Linear dependency should be fitted with almost zero error!'\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score < 1e-6, 'OOB error for linear dependency should be also close to zero!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Simple tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4d037",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Medium tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cfd3a21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edea8edd622a4b2f9058d44854c72a1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium tests done!\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(200, 150)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=20, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    average_train_error = np.mean((predictions - y)**2)\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score > average_train_error, 'OOB error must be higher than train error due to overfitting!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Medium tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725818ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Complex tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f929d6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f58f7d03703c40d7b942c88061b31535"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex tests done!\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(2000, 15)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=100, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 1e-2, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Complex tests done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af170ef8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-0.00041444117144234793"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535cb6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great job! Please, save `SimplifiedBaggingRegressor` to  `bagging.py` and submit your solution to the grading system!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Предлагается имплементировать в классическом стиле методы класса для Bagging Regressor, обучить и сравнить с пакетной реализацией.\n",
    "\n",
    "Реализуем сравнение через sklearn:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "X = np.random.randn(2000, 15)\n",
    "y = np.random.randn(len(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "-0.007742016269854268"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "br_sklearn = BaggingRegressor(LinearRegression(), oob_score=True)\n",
    "br_sklearn.fit(X, y)\n",
    "br_sklearn.predict(X)\n",
    "oob_score_sklearn = br_sklearn.oob_score_\n",
    "oob_score_sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.8 s\n",
      "Wall time: 21.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.00026444117144236445"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "br_custom = SimplifiedBaggingRegressor(num_bags=100, oob=True)\n",
    "br_custom.fit(LinearRegression, X, y)\n",
    "br_custom.predict(X)\n",
    "br_custom.OOB_score()\n",
    "abs(\n",
    "    np.mean(list(map(len, br_custom.list_of_predictions_lists))) / br_custom.num_bags - 1 / np.exp(1)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В результате сравнение нашего кастомного решения и коробочного из библиотеки sklearn видно, что коробочный за счет внутренней оптимизации работает на порядки раз быстрее, чем наше реализованное в ходе исследований.\n",
    "При этом абсолютная точность обоих решение не очень сильно отличается, но оба решения дают необходимую точность.\n",
    "\n",
    "**Коробочное решение на sklearn:**\n",
    "score: -0.007742016269854268\n",
    "время: 46.9 ms\n",
    "\n",
    "**Кастомное решение:**\n",
    "score: 0.00026444117144236445\n",
    "время: 21.8 s\n",
    "\n",
    "**Кастомное решение по результатам Complex tests:**\n",
    "score: -0.00041444117144234793"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}