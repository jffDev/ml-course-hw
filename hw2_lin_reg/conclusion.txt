В домашней работе было решено три учебных примера на матричное дифференцирование.
Примеры очень простые и решаются в одно действие. Ответы внесены в соответствующий раздел Warming up: matrix differentiation.

Далее было предложено реализовать функции потерь MSE и MAE, их производные и L1, L2 регуляризаторы.
Реализация функций находится в файле loss_and_derivatives.py, где реализован класс LossAndDerivatives.
Далее в рабочем ноутбуке были реализованы ассеты, по которым проверили нашу реализацию.

Также дополнительно добавил заполненный ноутбук assignment0_02_submission.ipynb с учебными заполненными ассетами для перепроверки реализации методов класса LossAndDerivatives.

Далее в ДЗ было предложено разобрать градиентный спуск на реальных данных, реализованный в функции get_w_by_grad.
Для тестирования и проверки использовался loss 'mse' и регуляризатор 'l2'.
В результате получили loss['mse'] равный loss['mse']=46.88

И в конце работы сравнили нашу реализацию с реализацией sklearn.
Sklearn посчитал loss равным loss['mse']=42.53

Также вывели график таргетов, получившихся от нашего решения и решения через библиотеку sklearn.
Как видим, решения получились практически идентичные и кастомное решение функции mse с l2 регуляризатором реализовано верно